---
output: pdf_document
---

## Inference  

Making inferences that go beyond the data at hand is a central focus of statistics, and both DTR estimation and response-adaptive randomization come with challenges that must be addressed when conducting statistical inference. Even in the non-contextual case inference about the value of a DTR requires tools beyond standard asymptotic theory because the value is a non-smooth functional of the data generating distribution; specifically, this nonsmoothness stems from DTR estimation involving either maximizing or minimizing the value function and both the max and min operators are nonsmooth. We won't discuss general issues with DTR estimation that are common to all data sources, but readers seeking further information about statistical inference for DTRs can consult \cite{tsiatis2019dynamic}. Inferential methods for analyzing data from response-adaptive randomization need to address the serial correlation in treatment assignment that occurs. Furthermore, response adaptive randomization methods may stop assigning inferior treatments too quickly for their effects to be estimated consistently in order to minimize the regret as quickly as possible. Finally, estimators are prone to non-uniform convergence where the rate of convergence (or indeed if it converges at all) depends on the value of the estimand. For a specific common example, when there is no difference in treatment effect between two interventions the allocation ratio for response-adaptive randomization methods may converge to a probability distribution instead of a constant corresponding to equal allocation. 

In response to these challenges, a multitude of approaches have been proposed in the literature including maintaining an independent estimation data set (or creating one algorithmically) \citep{li2011unbiased, li2013generalized}, ensuring each treatment is assigned sufficiently often in order to apply results from Martingale theory \citep{chen2021statistical}, more general adaptive weighting schemes that relax the variance assumptions necessary for the Martingale CLT \citep{hadad2021confidence, bibaut2021post}, and partitioning the sample size into batches and combining batch estimates normalized by the variance estimated for that batch \citep{zhang2021inference}, and others. To varying degrees these methods all include a design component (or imply constraints on the design of the study) in addition to the statistical component of the method to ensure that the assignment probability for inferior arms goes to zero slowly enough for inference to be possible. 

### Weighted Estimators 

```{=latex}

A major family of approaches is based on constraining the randomization probabilities so that the probability of assigning an arm doesn't go to zero too quickly or at all, and then use a test statistic based on Martingale theory \citep{chen2021statistical} or adaptive re-weighting \citep{bibaut2021post, hadad2021confidence}. \cite{chen2021statistical} show in the two-armed case that if the assignment probabilities converge to a nonzero constant $\phi^{\infty}$ then the Martingale CLT holds, the OLS estimator is unbiased, and for two-arms $k = 0, 1$
$$\sqrt{n} \left(\widehat{\beta}_{k,n} - \beta_{k,n} \right) \to_d \mathcal{N}(0, S_k) \quad k = 0, 1$$

where $$S_k = \sigma_k^2 \left(\frac{e^{\infty}}{2} \int_{\mathcal{X}_0 \cup \mathcal{X}_1} xx^T\,\mathrm{d}P(x)  + (1 - \phi^{\infty}\mathcal{X}_1)xx^T\,\mathrm{dP(x)}\right)^{-1}$$
and the sets $\mathcal{X}_0$ and $\mathcal{X}_1$ are defined respectively as $\mathcal{X}_0 = \{x: (\beta_1 - \beta_0)^Tx < 0 \}$ and $\mathcal{X}_1 = \{x: (\beta_1 - \beta_0)^Tx \geq 0 \}$. A consistent estimator of $S_k$ is 

$$\frac{\sum_{t = 1}^TI(a_t = k)\left(y_i - x_i^T \widehat{\beta}_{k} \right)^2}{\sum_{t = 1}^TI(a_t = k)} \left(\frac{1}{T} \sum_{t = 1}^T I(a_t = k) x_t x_t^T\right)^{-1}$$

Using the OLS estimator with an adjusted variance estimator is the most familiar approach, but it makes the strongest assumption about the limiting allocation probability. A more flexible approach is to use a weighted estimator. For a weighted estimator, the effective sample size for an arm after weighting must go to infinity rather than the unweighted sample size for that arm. Additionally the weights must satisfy certain conditions to prevent the variance from exploding, namely that the sum of the squared weights divided by the propensity scores converges in $L^p$ to the expected value of this summation and a bounded moments condition. These conditions are somewhat technical and interested readers should consult \cite{hadad2021confidence} and \cite{bibaut2021post}. The weights we discuss will satisfy these assumptions provided that the treatment propensity scores satisfy $\phi_t(k) \geq Ct^{-\alpha}$ for some $\alpha \in [0, 1)$ and any positive constants C. These authors take slightly different approaches to constructing weighted estimators but both rely on weighting to construct asymptotically normal estimators. Following \cite{hadad2021confidence}, we can break the process of constructing the weighted estimator into two steps: 1) choosing an unbiased estimator of the expected response, and then 2) choosing weights or, equivalently, an allocation rate.
These approaches allow for sublinear regret in contrast to the design-based approach that assign inferior treatments at a constant rate. 

The first step in constructing a weighted estimator is to choose an unbiased estimator of $\mathcal{V}(\pi) = E[Y^*(\pi)]$ where $Y^*(\pi)$ denotes the potential outcome if treatment were assigned according to policy $\pi$. We'll use $\mathcal{V}(k)$ to denote the expected response if treatment $k$ were always assigned. In order to construct an unbiased estimator of $\mathcal{V}(k)$, we'll construct an unbiased estimator of the expected response conditional on the history and assigned treatment $Q(h_t, a_t) :=  E[Y_t | \mathcal{H}_t = h_t, A_t = a_t]$ (where $\mathcal{H}_t$ includes $X_t$) and aggregate them. Following \cite{hadad2021confidence}, we'll define an unbiased scoring rule $\widehat{Q}_t$ for $Q(h_t, a_t)$ as any $\widehat{Q}_t$ that satisfies $\E \left[\widehat{Q}_t(h_t, a_t) | \mathcal{H}_t = h_t, A_t = a_t  \right] = Q(h_t, a_t)$ for all $h \in \mathcal{H}$ and $t = 1, \ldots, T$.  With an unbiased scoring rule in hand it's easy to construct an unbiased estimator of $\mathcal{V}(k)$. The IPW estimator is an unbiased estimator of $\mathcal{V}(k)$, and the corresponding unbiased scoring rule $\widehat{Q}_t^{\text{IPW}(k)} = I(A_t = k)Y_t/\phi_t(k)$ where $\phi_t(k) = P(A_t = k | \mathcal{H}_t)$. However, $\mathcal{V}(k)^{\text{IPA}}$ is not asymptotically normal, so we'll need to add variance stabilizing weights $w_t(k)$

$$\widehat{\mathcal{V}}_T^w(k) = \frac{\sum_{t = 1}^T w_t(k) \widehat{Q}_t^{\text{IPW}}(k)}{\sum_{t = 1}^T w_t(k)}$$

where $w_t$ satisfies

$$\frac{w_t^2(k)}{\phi(k)} = \left(1 - \sum_{i = 1}^{t-1}\frac{w_i(k)^2}{\phi_i(k)} \right) \lambda_t $$

\cite{hadad2021confidence} call $\lambda_t$ an allocation rate function, and it must satisfy $0 < \lambda_t < 1$ for all $t \in 1, \ldots, T - 1$ and $\lambda_T = 1$. This allocation rate function describes the fraction of the remaining variance allocated to the next observation. A simple option is a constant rate $\lambda_t^{\text{constant}} = \frac{1}{T - t + 1}$, but the variance of the estimator can be reduced with a better choice of allocation rate. They suggest the ``two-point allocation scheme'' when the randomization is done using Thompson Sampling which is derived from a mixture of the weights from assuming that either arm $k$ is optimal and so $\phi_t(k) \to 1$ as $t \to \infty$ or $\phi_t(k)$ converges to zero as fast as the lower bound  $\phi_t(k) \geq Ct^{-\alpha}$ permits. 

$$\lambda_t^{\text{two-point}} = \phi_t \frac{1}{T - t + 1} + (1 - \phi_t) \frac{t^{-\alpha}}{t^{-\alpha} + \frac{T^{1 - \alpha} - t^{1 -\alpha}}{1 - \alpha}}$$

Under either of these allocation ratios the estimator $\widehat{\mathcal{V}}_T^w(k)$ is consistent for $\mathcal{V}_T^w(k)$, and we can construct an asymptotically normal test statistic

$$\frac{\widehat{\mathcal{V}}_T^w(k) - \mathcal{V}_T^w(k)}{S_T^w(k)^{1/2}} \to_d \mathcal{N}(0, 1), \text{ where} \quad S_T^w(k) = \frac{\sum_{t = 1}^T w_t^2(k) \left(\widehat{Q}_t(k) - \widehat{\mathcal{V}}_T^w(k)\ \right)^2}{\left(\sum_{t = 1}^T w_t(k) \right)^2}$$
```